version: 2.1
orbs:
  hubploy:
    jobs:
      build-image:
        description: "Build an image via hubploy"
        parameters:
          deployment:
            type: string
          push:
            type: boolean
            default: false

        docker:
          - image: python:3.11-slim-bullseye
        working_directory: ~/repo
        resource_class: large
        steps:
          - checkout
          - run:
              name: Install git & curl
              command: |
                apt-get update && apt-get install --yes --no-install-recommends git curl
          - restore_cache:
              keys:
                - v3.11-dependencies-{{ checksum "requirements.txt" }}
                # fallback to using the latest cache if no exact match is found
                - v3.11-dependencies-

          - run:
              name: install dependencies
              command: |
                python3 -m venv venv
                source venv/bin/activate
                pip install --upgrade -r requirements.txt
                echo 'export PATH="${HOME}/repo/venv/bin:$PATH"' >> ${BASH_ENV}

          - unless:
              condition: << parameters.push >>
              steps:
                - run:
                    name: Determine range of commits we are building
                    command: |
                        # CircleCI doesn't have equivalent to Travis' COMMIT_RANGE
                        COMMIT_RANGE=$(./.circleci/get-commit-range.py 2> /tmp/commit-range-err.txt || true)
                        if [ -s /tmp/commit-range-err.txt ]; then
                            echo "Unable to get commit range."
                            cat /tmp/commit-range-err.txt
                            exit 1
                        fi
                        echo COMMIT_RANGE: ${COMMIT_RANGE}
                        echo "export COMMIT_RANGE='${COMMIT_RANGE}'" >> ${BASH_ENV}

          - when:
              condition: << parameters.push >>
              # Currently all our images live on google cloud, so we install gcloud sdk when pushing
              steps:
              - run:
                  name: Install google cloud sdk
                  command: |
                    export GCLOUD_URL=https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-457.0.0-linux-x86_64.tar.gz
                    curl -sSL $GCLOUD_URL | tar -xzf - -C ${HOME}
                    # Be careful with quote ordering here. ${PATH} must not be expanded
                    # Don't use ~ here - bash can interpret PATHs containing ~, but most other things can't.
                    # Always use full PATHs in PATH!
                    echo 'export PATH="${HOME}/google-cloud-sdk/bin:${PATH}"' >> ${BASH_ENV}
                    # Try to tell cloud sdk to use python3
                    echo 'export CLOUDSDK_PYTHON=python3' >> ${BASH_ENV}

              - run:
                  name: Install gcloud auth plugin
                  command: |
                    gcloud components install gke-gcloud-auth-plugin

              - run:
                  name: Configure credential helper for Google Artifact Registry
                  command: |
                    gcloud auth configure-docker us-central1-docker.pkg.dev

              - run:
                  name: Install sops
                  command: |
                    echo $SOPS_ACCOUNT_KEY > ${HOME}/repo/sops.key
                    echo 'export GOOGLE_APPLICATION_CREDENTIALS=${HOME}/repo/sops.key' >> ${BASH_ENV}
                    mkdir -p ${HOME}/repo/bin
                    curl -sSL https://github.com/mozilla/sops/releases/download/v3.7.0/sops-v3.7.0.linux -o ${HOME}/repo/bin/sops
                    chmod 755 ${HOME}/repo/bin/sops
                    echo 'export PATH="${HOME}/repo/bin:${PATH}"' >> ${BASH_ENV}

          - setup_remote_docker
          - save_cache:
              paths:
                - ./venv
              key: v3.11-dependencies-{{ checksum "requirements.txt" }}

          - run:
              name: Build image if needed
              command: |
                if [ "<< parameters.push >>" == "true" -o -z "${COMMIT_RANGE}" ]; then
                  HUBPLOY_ARGS="--check-registry --push"
                else
                  HUBPLOY_ARGS="--commit-range ${COMMIT_RANGE}"
                fi
                hubploy build << parameters.deployment >>  ${HUBPLOY_ARGS}
              no_output_timeout: 90m

jobs:
  deploy:
    docker:
      - image: python:3.11-slim-bullseye
    working_directory: ~/repo
    steps:
      - run:
          name: Install base apt packages
          command: |
            apt-get update -qq --yes
            apt-get install -qq --yes git curl lsb-release apt-transport-https
      - checkout
      # Download and cache dependencies
      - restore_cache:
          keys:
            - v3.11-dependencies-gcloud-457-{{ checksum "requirements.txt" }}
            # fallback to using the latest cache if no exact match is found
            - v3.11-dependencies-gcloud-457-

      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade -r requirements.txt

            # Can be removed once https://github.com/docker/docker-py/issues/2225 is merged and released
            pip install --upgrade git+https://github.com/docker/docker-py.git@b6f6e7270ef1acfe7398b99b575d22d0d37ae8bf

            export GCLOUD_URL=https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-457.0.0-linux-x86_64.tar.gz
            curl -sSL $GCLOUD_URL | tar -xzf - -C ${HOME}
            # Be careful with quote ordering here. ${PATH} must not be expanded
            # Don't use ~ here - bash can interpret PATHs containing ~, but most other things can't.
            # Always use full PATHs in PATH!
            echo 'export PATH="${HOME}/repo/venv/bin:${HOME}/google-cloud-sdk/bin:${PATH}"' >> ${BASH_ENV}

            curl -sSL https://github.com/mozilla/sops/releases/download/v3.7.0/sops-v3.7.0.linux -o venv/bin/sops
            chmod 755 venv/bin/sops

      - save_cache:
          paths:
            - ./venv
          key: v3.11-dependencies-gcloud-457-{{ checksum "requirements.txt" }}

      - run:
          name: Authenticating with google service account for kms/sops
          command: |
            echo $SOPS_ACCOUNT_KEY > ${HOME}/repo/sops.key
            echo 'export GOOGLE_APPLICATION_CREDENTIALS=${HOME}/repo/sops.key' >> ${BASH_ENV}

      - run:
          name: Install helm3
          command: |
            curl -L https://get.helm.sh/helm-v3.13.3-linux-amd64.tar.gz | \
              tar -xzf -
            mv linux-amd64/helm /usr/local/bin
            helm repo add jupyterhub https://jupyterhub.github.io/helm-chart/
            helm repo update

      - run:
          name: Post annotation to Grafana
          command: |
            # We get GRAFANA_API_KEY from circle secret config. FIXME: put this inside git-crypt
            export PULL_REQUEST_ID=$(git log -1 --pretty=%B | head -n1 | sed 's/^.*#\([0-9]*\).*/\1/')
            export AUTHOR_NAME="$(git log  -1 --pretty=%aN)"
            export PULL_REQUEST_TITLE="$(git log --pretty=%B -1 | tail -n+3)"

            # added by sknapp 2023-12-19 to unblock builds
            # python3 scripts/post-grafana-annotation.py  \
            #   --grafana-url http://grafana.datahub.berkeley.edu\
            #   --tag deployment-start \
            #  "$(echo -en ${PULL_REQUEST_TITLE}\\n\\n${AUTHOR_NAME}: https://github.com/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/pull/${PULL_REQUEST_ID})"
      - run:
          name: Install gcloud auth plugin
          command: |
            gcloud components install gke-gcloud-auth-plugin

      - run:
          name: Deploy data8
          command: |
            hubploy deploy --timeout 30m data8 hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy data100
          command: |
            hubploy deploy --timeout 30m data100 hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy data102
          command: |
            hubploy deploy --timeout 30m data102 hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy datahub
          command: |
            hubploy deploy --timeout 30m datahub hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy dlab
          command: |
            hubploy deploy --timeout 30m dlab hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy edx
          command: |
            hubploy deploy --timeout 30m edx hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy highschool hub
          command: |
            hubploy deploy --timeout 30m highschool hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy ischool
          command: |
            hubploy deploy --timeout 30m ischool hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy prob140
          command: |
            hubploy deploy --timeout 30m prob140 hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy R
          command: |
            hubploy deploy --timeout 30m r hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

      - run:
          name: Deploy workshop
          command: |
            hubploy deploy --timeout 30m workshop hub ${CIRCLE_BRANCH}
          no_output_timeout: 30m

workflows:
  version: 2
  test-build-images:
    jobs:
      - hubploy/build-image:
          deployment: data8
          name: data8 image build
          # Filters can only be per-job? wtf
          filters:
              branches:
                ignore:
                - staging
                - prod
      - hubploy/build-image:
          deployment: data100
          name: data100 image build
          # Filters can only be per-job? wtf
          filters:
              branches:
                ignore:
                - staging
                - prod
      - hubploy/build-image:
          deployment: data102
          name: data102 image build
          filters:
              branches:
                ignore:
                - staging
                - prod
      - hubploy/build-image:
          deployment: datahub
          # Workshop hub also uses this
          name: datahub image build
          # Filters can only be per-job? wtf
          filters:
              branches:
                ignore:
                - staging
                - prod
      - hubploy/build-image:
          deployment: edx
          name: edx image build
          # Filters can only be per-job? wtf
          filters:
              branches:
                ignore:
                - staging
                - prod
      - hubploy/build-image:
          deployment: ischool
          name: ischool image build
          # Filters can only be per-job? wtf
          filters:
              branches:
                ignore:
                - staging
                - prod

  deploy:
    jobs:
      - hubploy/build-image:
          deployment: data8
          name: data8 image build
          push: true
          # Filters can only be per-job? wtf
          filters:
              branches:
                only:
                - staging
      - hubploy/build-image:
          deployment: data100
          name: data100 image build
          push: true
          filters:
              branches:
                only:
                - staging
      - hubploy/build-image:
          deployment: data102
          name: data102 image build
          push: true
          filters:
              branches:
                only:
                - staging
      - hubploy/build-image:
          # workshop hub also uses this image
          deployment: datahub
          name: datahub image build
          push: true
          # Filters can only be per-job? wtf
          filters:
              branches:
                only:
                - staging
      - hubploy/build-image:
          deployment: edx
          name: edx image build
          push: true
          # Filters can only be per-job? wtf
          filters:
              branches:
                only:
                - staging
      - hubploy/build-image:
          deployment: ischool
          name: ischool image build
          push: true
          # Filters can only be per-job? wtf
          filters:
              branches:
                only:
                - staging
      # Build images only during the staging deploy. All merges
      # to prod need to go via staging, so prod should *never*
      # use images not built for staging. By enforcing this at the
      # CI level, we also make prod deploys go faster!
      - deploy:
          requires:
              - data8 image build
              - data100 image build
              - data102 image build
              - datahub image build
              - edx image build
              - ischool image build

          filters:
            branches:
              only:
                - staging
      - deploy:
          filters:
            branches:
              only:
                - prod
