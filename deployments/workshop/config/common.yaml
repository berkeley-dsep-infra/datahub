nfsPVC:
  enabled: true
  nfs:
    serverIP: nfsserver-01
    shareName: export/homedirs-other-2020-07-29/workshop

jupyterhub:
  prePuller:
    continuous:
      # Same image as datahub, so no continouus pre-puller needed
      enabled: false
  cull:
    # Cull after 30min of inactivity
    every: 300
    timeout: 1800
    # No pods over 12h long, no workshop is gonna be more than that :)
    maxAge: 43200
  scheduling:
    userScheduler:
      nodeSelector:
        hub.jupyter.org/pool-name: core-pool
  hub:
    # No more than 200 users at any given time
    activeServerLimit: 200
    nodeSelector:
      hub.jupyter.org/pool-name: core-pool
    config:
      JupyterHub:
        admin_access: false
        authenticator_class: dummy
  proxy:
    nodeSelector:
      hub.jupyter.org/pool-name: core-pool
  singleuser:
    nodeSelector:
      # Co-locate with datahub, since workshop shares its image
      hub.jupyter.org/pool-name: alpha-pool
    image:
      # Matches datahub image
      name: gcr.io/ucb-datahub-2018/primary-user-image
    storage:
      type: static
      static:
        pvcName: home-nfs
        subPath: "{username}"
      extraVolumes:
        - name: etc-jupyter
          configMap:
            name: user-etc-jupyter
      extraVolumeMounts:
        - name: etc-jupyter
          mountPath: /etc/jupyter
    memory:
      # As low a guarantee as possible
      guarantee: 128M
      limit: 1G
